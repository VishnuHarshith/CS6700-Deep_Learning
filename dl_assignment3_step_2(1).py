# -*- coding: utf-8 -*-
"""DL_Assignment3_Step 2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tP7tofaBEHHm1CTCGB62t7wTW3YEaFdN
"""

import torch
import torchvision.models as models

# Commented out IPython magic to ensure Python compatibility.
import keras
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
import pandas as pd
import cv2
import numpy as np
from matplotlib import pyplot as plt
from sklearn.metrics import confusion_matrix
import itertools
from keras.layers import Dense, Dropout, Activation, Flatten, Input
from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D
from keras.layers import BatchNormalization
from keras.regularizers import l2
from keras.models import Model
from keras.optimizers import Adam, RMSprop, SGD, Adadelta, Adagrad
from keras.callbacks import LearningRateScheduler
from keras import backend as K
from keras.applications.vgg16 import VGG16


# %matplotlib inline

from google.colab import drive

drive.mount("/content/gdrive")

# data_path = '/content/gdrive/My Drive/Images_Round2_Class21/'
# # we'll use data from two folders
shelf_images = "/content/gdrive/My Drive/DL_Assignment_3/CUB_200_2011/images/"
# product_images = '/content/gdrive/My Drive/Images_Round2_Class21/Dataset_Final_Class_21/p'

import pandas as pd

# load data from previous step
train_data = pd.read_csv(
    "/content/gdrive/My Drive/DL_Assignment_3/train_data_team43.csv"
)

# load data from previous step
val_data = pd.read_csv(
    "/content/gdrive/My Drive/DL_Assignment_3/validation_data_team43.csv"
)

test_data = pd.read_csv("/content/gdrive/My Drive/DL_Assignment_3/test_data_team43.csv")

test_data.shape

# neural networks work with input of fixed size, so we need to resize our
# packs images to the chosen size. The size is some kind of metaparameter and
# you should try different variants. Logically, the bigger size you select,
# the better performace you'll have. Unfortunatelly it is not true, because
# of over fitting. The more parameters your neural network have, the easier it
# became over fitted
num_classes = 7
SHAPE_WIDTH = 299
SHAPE_HEIGHT = 299

# resize pack to fixed size SHAPE_WIDTH x SHAPE_HEIGHT
def resize_pack(pack):
    fx_ratio = SHAPE_WIDTH / pack.shape[1]
    fy_ratio = SHAPE_HEIGHT / pack.shape[0]
    pack = cv2.resize(pack, (0, 0), fx=fx_ratio, fy=fy_ratio)
    return pack[0:SHAPE_HEIGHT, 0:SHAPE_WIDTH]


# x - image, y - class, f - is_train flag
x, y, f = [], [], []
for file, is_train in train_data[["file", "is_train"]].values:
    photo_rects = train_data[train_data.file == file]
    rects_data = photo_rects[["label", "xmin", "ymin", "xmax", "ymax"]]
    im = cv2.imread(f"{shelf_images}{file}")
    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)
    for category, xmin, ymin, xmax, ymax in rects_data.values:
        pack = resize_pack(np.array(im[ymin:ymax, xmin:xmax]))
        x.append(pack)
        f.append(is_train)
        y.append(category)

# display one SHAPE_WIDTH x SHAPE_HEIGHT resized pack image,
# it is hard to recognize category with our eyes, let's see
# how neural network will do the job
plt.imshow(x[5])


# let's split the data to train/validation sets based on our is_train flag
x_train = np.array(x)
# x_train, x_validation, y_train, y_validation = x[f], x[~f], y[f], y[~f]
# # save validation images
# x_validation_images = x_validation

for i in range(len(y)):
    if y[i] == 20:
        y[i] = 0
    elif y[i] == 41:
        y[i] = 1
    elif y[i] == 95:
        y[i] = 2
    elif y[i] == 114:
        y[i] = 3
    elif y[i] == 128:
        y[i] = 4
    elif y[i] == 131:
        y[i] = 5
    elif y[i] == 135:
        y[i] = 6

y_train = np.array(y)

y_train

# x - image, y - class, f - is_train flag
x, y, f = [], [], []
for file, is_train in val_data[["file", "is_train"]].values:
    photo_rects = val_data[val_data.file == file]
    rects_data = photo_rects[["label", "xmin", "ymin", "xmax", "ymax"]]
    im = cv2.imread(f"{shelf_images}{file}")
    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)
    for category, xmin, ymin, xmax, ymax in rects_data.values:
        pack = resize_pack(np.array(im[ymin:ymax, xmin:xmax]))
        x.append(pack)
        f.append(is_train)
        y.append(category)

x_validation = np.array(x)

for i in range(len(y)):
    if y[i] == 20:
        y[i] = 0
    elif y[i] == 41:
        y[i] = 1
    elif y[i] == 95:
        y[i] = 2
    elif y[i] == 114:
        y[i] = 3
    elif y[i] == 128:
        y[i] = 4
    elif y[i] == 131:
        y[i] = 5
    elif y[i] == 135:
        y[i] = 6

y_validation = np.array(y)

y_validation

plt.imshow(x_validation[4])

# x - image, y - class, f - is_train flag
x, y, f = [], [], []
for file, is_train in test_data[["file", "is_train"]].values:
    photo_rects = test_data[test_data.file == file]
    rects_data = photo_rects[["label", "xmin", "ymin", "xmax", "ymax"]]
    im = cv2.imread(f"{shelf_images}{file}")
    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)
    for category, xmin, ymin, xmax, ymax in rects_data.values:
        pack = resize_pack(np.array(im[ymin:ymax, xmin:xmax]))
        x.append(pack)
        f.append(is_train)
        y.append(category)

x_test = np.array(x)

for i in range(len(y)):
    if y[i] == 20:
        y[i] = 0
    elif y[i] == 41:
        y[i] = 1
    elif y[i] == 95:
        y[i] = 2
    elif y[i] == 114:
        y[i] = 3
    elif y[i] == 128:
        y[i] = 4
    elif y[i] == 131:
        y[i] = 5
    elif y[i] == 135:
        y[i] = 6

y_test = np.array(y)

y_test

plt.imshow(x_test[3])

# convert y_train and y_validation to one-hot arrays
y_train = keras.utils.to_categorical(y_train, num_classes)
y_validation = keras.utils.to_categorical(y_validation, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)

# normalize x_train, x_validation
x_train = x_train.astype("float32")
x_validation = x_validation.astype("float32")
x_test = x_test.astype("float32")
x_train /= 255
x_validation /= 255
x_test /= 255

y_test.shape

# let's see what do we have
print("x_train shape:", x_train.shape)
print("y_train shape:", y_train.shape)
print(x_train.shape[0], "train samples")
print(x_validation.shape[0], "validation samples")

from keras.models import Model
from keras.layers import Dense
from keras import optimizers
from keras.preprocessing.image import ImageDataGenerator
from keras.preprocessing import image

"""### VGG Model"""

from keras.applications.vgg16 import VGG16

vggmodel = VGG16(weights="imagenet", include_top=True)

vggmodel.summary()

for layers in (vggmodel.layers)[:19]:
    print(layers)
    layers.trainable = False

X = vggmodel.layers[-2].output
predictions = Dense(7, activation="softmax")(X)
model_final = Model(input=vggmodel.input, output=predictions)

model_final.compile(
    loss="categorical_crossentropy",
    optimizer=optimizers.Adam(lr=0.001),
    metrics=["accuracy"],
)

model_final.summary()

# This will do preprocessing and realtime data augmentation:
datagen = ImageDataGenerator(
    featurewise_center=False,  # set input mean to 0 over the dataset
    samplewise_center=False,  # set each sample mean to 0
    featurewise_std_normalization=False,  # divide inputs by std of the dataset
    samplewise_std_normalization=False,  # divide each input by its std
    zca_whitening=False,  # apply ZCA whitening
    rotation_range=5,  # randomly rotate images in the range (degrees, 0 to 180)
    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)
    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)
    horizontal_flip=False,  # randomly flip images
    vertical_flip=False,
)  # randomly flip images
datagen.fit(x_train)

# let's run training process, 20 epochs is enough
batch_size = 32
epochs = 300
history = model_final.fit_generator(
    datagen.flow(x_train, y_train, batch_size=batch_size),
    validation_data=(x_validation, y_validation),
    epochs=epochs,
    verbose=1,
    workers=4,
)

import pickle

filename = "/content/gdrive/My Drive/DL_Assignment_3/vggmodel_Adam32.sav"
pickle.dump(model_final, open(filename, "wb"))

# let's estimate our result
scores = model_final.evaluate(x_test, y_test, verbose=1)
print("Test loss:", scores[0])
print("Test accuracy:", scores[1])

model_final.summary()

fc2 = model_final.get_layer("block5_pool").output
# f0 = Flatten()(block5_conv3)

test_model_vgg = Model(inputs=model_final.input, outputs=fc2)


from keras.models import Sequential
from keras.layers import Dense, Conv2D, MaxPool2D, Flatten
from keras.preprocessing.image import ImageDataGenerator
import numpy as np

# model = Sequential()
# model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding="same", activation="relu"))
# model.add(Conv2D(filters=64,kernel_size=(3,3),padding="same", activation="relu"))
# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
# model.add(Conv2D(filters=128, kernel_size=(3,3), padding="same", activation="relu"))
# model.add(Conv2D(filters=128, kernel_size=(3,3), padding="same", activation="relu"))
# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
# model.add(Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu"))
# model.add(Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu"))
# model.add(Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu"))
# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
# model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
# model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
# model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
# model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
# model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
# model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
# model.add(Flatten())
# model.add(Dense(units=4096,activation="relu"))
# model.add(Dense(units=4096,activation="relu"))
# model.add(Dense(units=7, activation="softmax"))

# from keras.optimizers import Adam
# opt = Adam(lr=0.001)
# model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])

from keras.callbacks import ModelCheckpoint, EarlyStopping

# checkpoint = ModelCheckpoint("/content/gdrive/My Drive/DL_Assignment_3/vgg16_1.h5", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)
# early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')

from keras.applications.vgg16 import preprocess_input

xp_train = preprocess_input(x_train)
xp_val = preprocess_input(x_validation)

xp_test = preprocess_input(x_test)

xp_test.shape

model_final.fit(
    x=xp_train, y=y_train, validation_data=(xp_val, y_validation), verbose=1, epochs=50
)

model_final.summary()

fc2 = model_final.get_layer("fc1").output
# f0 = Flatten()(block5_conv3)

test_model_vgg = Model(inputs=model_final.input, outputs=fc2)

from keras.applications.vgg16 import preprocess_input

# prepare the image for the VGG model
# x_train_processed = preprocess_input(x_train)
# x_val_processed = preprocess_input(x_validation)
xp_test = preprocess_input(x_test)

fc_vgg_train = test_model_vgg.predict(x_train)

fc_vgg_train.shape

fc_vgg_val = test_model_vgg.predict(x_validation)

fc_vgg_test = test_model_vgg.predict(x_test)

fc_vgg_test.shape

import numpy as np

np.save("vggtrain", fc_vgg_train)

np.save("vggval", fc_vgg_val)

np.save("vggtest", fc_vgg_test)


fc_vgg_val.shape

import numpy as np

np.savetxt(
    "/content/gdrive/My Drive/DL_Assignment_3/vgg_train.csv",
    fc_vgg_train,
    delimiter=",",
)

np.savetxt(
    "/content/gdrive/My Drive/DL_Assignment_3/vgg_val.csv", fc_vgg_val, delimiter=","
)

np.savetxt(
    "/content/gdrive/My Drive/DL_Assignment_3/vgg_test.csv", fc_vgg_test, delimiter=","
)

"""### Google Net"""

from keras.applications import InceptionV3

googlenet_model = InceptionV3(weights="imagenet", include_top=True)

googlenet_model.summary()

len(googlenet_model.layers)

for layers in (googlenet_model.layers)[:309]:
    print(layers)
    layers.trainable = False

X = googlenet_model.layers[-2].output
predictions = Dense(7, activation="softmax")(X)
model_final = Model(input=googlenet_model.input, output=predictions)

model_final.summary()

model_final.compile(
    loss="categorical_crossentropy",
    optimizer=optimizers.Adam(lr=0.001),
    metrics=["accuracy"],
)

# This will do preprocessing and realtime data augmentation:
datagen = ImageDataGenerator(
    featurewise_center=False,  # set input mean to 0 over the dataset
    samplewise_center=False,  # set each sample mean to 0
    featurewise_std_normalization=False,  # divide inputs by std of the dataset
    samplewise_std_normalization=False,  # divide each input by its std
    zca_whitening=False,  # apply ZCA whitening
    rotation_range=5,  # randomly rotate images in the range (degrees, 0 to 180)
    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)
    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)
    horizontal_flip=False,  # randomly flip images
    vertical_flip=False,
)  # randomly flip images
datagen.fit(x_train)

# let's run training process, 20 epochs is enough
batch_size = 32
epochs = 300
history = model_final.fit_generator(
    datagen.flow(x_train, y_train, batch_size=batch_size),
    validation_data=(x_validation, y_validation),
    epochs=epochs,
    verbose=1,
    workers=4,
)


fc2 = model_final.get_layer("mixed10").output
# f0 = Flatten()(block5_conv3)

test_model_vgg = Model(inputs=model_final.input, outputs=fc2)

fc_vgg_train = test_model_vgg.predict(x_train)
fc_vgg_val = test_model_vgg.predict(x_validation)
fc_vgg_test = test_model_vgg.predict(x_test)

fc_vgg_test.shape

np.save("/content/gdrive/My Drive/DL_Assignment_3/gnettrain.npy", fc_vgg_train)

np.save("/content/gdrive/My Drive/DL_Assignment_3/gnetval.npy", fc_vgg_val)

np.save("/content/gdrive/My Drive/DL_Assignment_3/gnettest.npy", fc_vgg_test)

np.savetxt(
    "/content/gdrive/My Drive/DL_Assignment_3/googlenet_train.csv",
    fc_vgg_train,
    delimiter=",",
)

np.savetxt(
    "/content/gdrive/My Drive/DL_Assignment_3/googlenet_val.csv",
    fc_vgg_val,
    delimiter=",",
)

np.savetxt(
    "/content/gdrive/My Drive/DL_Assignment_3/googlenet_test.csv",
    fc_vgg_test,
    delimiter=",",
)

# use the keras functional api
reg_val = 0
X_train, X_val, y_train, y_val = train_test_split(
    img_red, true_labels, test_size=0.2, random_state=1234
)
inputs = tf.keras.Input(shape=(300,))
x = tf.keras.layers.Dense(
    80,
    activation="relu",
    kernel_regularizer=tf.keras.regularizers.l2(reg_val),
    bias_regularizer=tf.keras.regularizers.l2(reg_val),
)(inputs)
x = tf.keras.layers.Dropout(0.2)(x)
x = tf.keras.layers.Dense(
    70,
    activation="relu",
    kernel_regularizer=tf.keras.regularizers.l2(reg_val),
    bias_regularizer=tf.keras.regularizers.l2(reg_val),
)(x)
x = tf.keras.layers.Dropout(0.2)(x)
outputs = tf.keras.layers.Dense(5)(x)
model = tf.keras.Model(inputs=inputs, outputs=outputs, name="Task_1_part_1")
callback = tf.keras.callbacks.EarlyStopping(monitor="val_loss", patience=4)
model.compile(
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    optimizer=tf.keras.optimizers.Adam(1e-4),
    metrics=["accuracy"],
)
history = model.fit(
    X_train,
    y_train,
    epochs=3000,
    batch_size=128,
    callbacks=[callback],
    validation_data=(X_val, y_val),
    verbose=0,
)


def plot_confusion_matrix(
    cm, classes, normalize=False, title="Confusion matrix", cmap=plt.cm.Blues
):
    if normalize:
        cm = cm.astype("float") / cm.sum(axis=1)[:, np.newaxis]
    plt.imshow(cm, interpolation="nearest", cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = ".2f" if normalize else "d"
    thresh = cm.max() / 2.0
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(
            j,
            i,
            format(cm[i, j], fmt),
            horizontalalignment="center",
            color="white" if cm[i, j] > thresh else "black",
        )

    plt.tight_layout()
    plt.ylabel("True label")
    plt.xlabel("Predicted label")


# let's draw confusion matrix to check classes recognition performance
y_validation_cls = np.argmax(y_validation, axis=1)
y_validation_predict = model.predict(x_validation)
y_validation_predict_cls = np.argmax(y_validation_predict, axis=1)

fig = plt.gcf()
fig.set_size_inches(10, 10)
cnf_matrix = confusion_matrix(y_validation_cls, y_validation_predict_cls)
plot_confusion_matrix(
    cnf_matrix,
    [f"C{i+1}" for i in range(num_classes)],
    title="Confusion matrix",
    normalize=True,
)
